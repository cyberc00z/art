#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, sys
import json
import random
from requests import get
from bs4 import BeautifulSoup

class Extractor:
    def __init__(self, url: str):
        self.__url = url
    
    def _send_request(self) -> BeautifulSoup:
        reqs = get(self.__url)
        soup = BeautifulSoup(reqs.text, 'html.parser')
        return soup
    
    def save_results(self, response: BeautifulSoup) -> None:
        urls = []
        for link in response.find_all('a'):
              #print(f"[*] Link: {link.get('href')}")
              json_format = {
                   "url" : f"http://artscene.textfiles.com/ansi/unsorted/" + f"{link.get('href')}"
              }
              json_data = json_format
              data = []
              print(json_data)
              #written_lines = 0
              with open('links.json', 'w') as outfile:
                   for link in list(json_data.items()):
                       data = data.append(json.loads(str(link)))
                       #json.dumps(link, outfile)
                       #written_lines = written_lines + 1  
                  

url = 'http://artscene.textfiles.com/ansi/unsorted/'
#print(url)
extractor = Extractor(url)
response = extractor._send_request()
extractor.save_results(response)
